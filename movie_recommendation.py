# -*- coding: utf-8 -*-
"""Movie_recommendation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1k1czskKL4oJ3aKh6FE-rna1hG0pJ6xWN
"""

import string
import re
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import tensorflow as tf
import tensorflow_recommenders as tfrs
from collections import Counter
from typing import Dict, Text
from ast import literal_eval
from datetime import datetime
from wordcloud import WordCloud
from sklearn.preprocessing import MinMaxScaler
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

import warnings
warnings.filterwarnings('ignore')

tfidf = TfidfVectorizer(stop_words='english', min_df=5)

!pip install tensorflow_recommenders

content_df = pd.read_csv('content_df.csv');
content_df.head(50)

import pickle

with open('cosine_similarity.pkl', 'rb') as file:
    tfidf_matrix = pickle.load(file)

cos_sim = cosine_similarity(tfidf_matrix)
cos_sim.shape

def predict(title, similarity_weight=0.7, top_n=10):
    data = content_df.reset_index()
    index_movie = data[data['original_title'] == title].index
    similarity = cos_sim[index_movie].T

    sim_df = pd.DataFrame(similarity, columns=['similarity'])
    final_df = pd.concat([data, sim_df], axis=1)
    # You can also play around with the number
    final_df['final_score'] = final_df['score']*(1-similarity_weight) + final_df['similarity']*similarity_weight

    final_df_sorted = final_df.sort_values(by='final_score', ascending=False).head(top_n)
    final_df_sorted.set_index('original_title', inplace=True)
    return final_df_sorted[['score', 'similarity', 'final_score']]

predict("The Godfather: Part II", similarity_weight=0.9, top_n=6)

# content_df.head(50)

ratings_df = pd.read_csv('ratings_df.csv')

print(len(ratings_df))

movies_df = pd.read_csv('movies_df.csv')

print(len(movies_df))

ratings_df['userId'] = ratings_df['userId'].astype(str)

ratings = tf.data.Dataset.from_tensor_slices(dict(ratings_df[['userId', 'original_title', 'rating']]))
movies = tf.data.Dataset.from_tensor_slices(dict(movies_df[['original_title']]))

ratings = ratings.map(lambda x: {
    "original_title": x["original_title"],
    "userId": x["userId"],
    "rating": float(x["rating"])
})

movies = movies.map(lambda x: x["original_title"])

print('Total Data: {}'.format(len(ratings)))

tf.random.set_seed(42)
shuffled = ratings.shuffle(100_000, seed=42, reshuffle_each_iteration=False)

train = ratings.take(35_000)
test = ratings.skip(35_000).take(8_188)

movie_titles = movies.batch(1_000)
user_ids = ratings.batch(1_000).map(lambda x: x["userId"])

unique_movie_titles = np.unique(np.concatenate(list(movie_titles)))
unique_user_ids = np.unique(np.concatenate(list(user_ids)))

print('Unique Movies: {}'.format(len(unique_movie_titles)))
print('Unique users: {}'.format(len(unique_user_ids)))

class MovieModel(tfrs.models.Model):

  def __init__(self, unique_user_ids, unique_movie_titles, rating_weight: float, retrieval_weight: float) -> None:
    super().__init__()

    embedding_dimension = 64

    # User and movie models.
    self.movie_model = tf.keras.Sequential([
      tf.keras.layers.StringLookup(
        vocabulary=unique_movie_titles, mask_token=None),
      tf.keras.layers.Embedding(len(unique_movie_titles) + 1, embedding_dimension)
    ])
    self.user_model = tf.keras.Sequential([
      tf.keras.layers.StringLookup(
        vocabulary=unique_user_ids, mask_token=None),
      tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)
    ])

    # A small model to take in user and movie embeddings and predict ratings.
    self.rating_model = tf.keras.Sequential([
        tf.keras.layers.Dense(256, activation="relu"),
        tf.keras.layers.Dense(128, activation="relu"),
        tf.keras.layers.Dense(1),
    ])

    # The tasks.
    self.rating_task = tfrs.tasks.Ranking(
        loss=tf.keras.losses.MeanSquaredError(),
        metrics=[tf.keras.metrics.RootMeanSquaredError()],
    )
    self.retrieval_task = tfrs.tasks.Retrieval(
        metrics=tfrs.metrics.FactorizedTopK(
            candidates=movies.batch(128).map(self.movie_model)
        )
    )

    # The loss weights.
    self.rating_weight = rating_weight
    self.retrieval_weight = retrieval_weight

  def call(self, features: Dict[Text, tf.Tensor]) -> tf.Tensor:
    user_embeddings = self.user_model(features["userId"])
    movie_embeddings = self.movie_model(features["original_title"])
    rating_predictions = self.rating_model(tf.concat([user_embeddings, movie_embeddings], axis=1))
    return user_embeddings, movie_embeddings, rating_predictions

  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:
    ratings = features.pop("rating")
    user_embeddings, movie_embeddings, rating_predictions = self(features)

    rating_loss = self.rating_task(labels=ratings, predictions=rating_predictions)
    retrieval_loss = self.retrieval_task(user_embeddings, movie_embeddings)

    return self.rating_weight * rating_loss + self.retrieval_weight * retrieval_loss

model = MovieModel(unique_user_ids, unique_movie_titles, rating_weight=1.0, retrieval_weight=1.0)

dummy_user = tf.constant(["dummy"])
dummy_movie = tf.constant(["dummy"])
model({"userId": dummy_user, "original_title": dummy_movie})

model.load_weights('tfrs.h5')

def predict_movie(user, top_n=3):
    index = tfrs.layers.factorized_top_k.BruteForce(model.user_model)
    index.index_from_dataset(
        tf.data.Dataset.zip((movies.batch(100), movies.batch(100).map(model.movie_model)))
    )
    _, titles = index(tf.constant([str(user)]))
    print(f'Top {top_n} recommendations for user {user}:\n')
    for i, title in enumerate(titles[0, :top_n].numpy()):
        print(f'{i+1}. {title.decode("utf-8")}')

# Function to predict rating for a movie
def predict_rating(user, movie):
    user_embeddings, movie_embeddings, rating_prediction = model({
        "userId": tf.constant([str(user)]),
        "original_title": tf.constant([movie])
    })
    print(f"Predicted rating for {movie}: {rating_prediction.numpy()[0][0]}")

# Example usage:
predict_movie("100")

predict_rating("100","Dont Look Back")

ratings_df[ratings_df['userId'] == '50'][['original_title','genres','rating']].sort_values(by='rating', ascending=False)

predict_movie('50')

